{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFbjAAa98AwJ3hFvx4EAX9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sibhap/CSE_6250_Project/blob/master/KSI%2BLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebgzDE0YM-rv",
        "outputId": "543bf8f9-c797-4eaf-8427-003db4defe45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stop-words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5N9f7BtyjnKt",
        "outputId": "634c7c0e-4a05-4822-aa27-f0634184ba59"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting stop-words\n",
            "  Downloading stop-words-2018.7.23.tar.gz (31 kB)\n",
            "Building wheels for collected packages: stop-words\n",
            "  Building wheel for stop-words (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stop-words: filename=stop_words-2018.7.23-py3-none-any.whl size=32912 sha256=0790b1c80423a4820a01ebc301794bd3b9a30f08cf7927652de2d76a3a53e011\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/86/b2/277b10b1ce9f73ce15059bf6975d4547cc4ec3feeb651978e9\n",
            "Successfully built stop-words\n",
            "Installing collected packages: stop-words\n",
            "Successfully installed stop-words-2018.7.23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/My Drive/CS6250"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgErSZzcl1nA",
        "outputId": "e11e4685-8066-4c04-93dc-115947e93c78"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/CS6250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python preprocessing1.py"
      ],
      "metadata": {
        "id": "3r4U1W_vl_0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python preprocessing2.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pw_cg2z8mCo0",
        "outputId": "766b7f53-e6a6-45ef-b633-9f0168a65a75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tcmalloc: large alloc 5134286848 bytes == 0x5c50a000 @  0x7ff2b05b7001 0x7ff2adf461af 0x7ff2adf9cc23 0x7ff2adf9da87 0x7ff2ae03f823 0x58f62c 0x510bf2 0x58fd37 0x510325 0x5b4ee6 0x58ff2e 0x510325 0x4bac0a 0x4d3249 0x5917ee 0x591ac9 0x539167 0x50cb08 0x5b4ee6 0x6005a3 0x607796 0x60785c 0x60a436 0x64db82 0x64dd2e 0x7ff2b01b2c87 0x5b636a\n",
            "tcmalloc: large alloc 5134286848 bytes == 0x18f328000 @  0x7ff2b05b51e7 0x7ff2adf460ce 0x7ff2adfa0726 0x7ff2adfa0b09 0x7ff2adfa2620 0x7ff2adfa2d1b 0x7ff2ae043333 0x58f62c 0x510bf2 0x5b4ee6 0x6005a3 0x607796 0x60785c 0x60a436 0x64db82 0x64dd2e 0x7ff2b01b2c87 0x5b636a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python preprocessing3.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mINThiInzxQ",
        "outputId": "95bc3ab7-5f42-4125-e9a8-fa3833b2b819"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tcmalloc: large alloc 5134286848 bytes == 0x1f1a2000 @  0x7f99eb4d81e7 0x7f99e8e290ce 0x7f99e8e80e57 0x7f99e8e81a6f 0x7f99e8f27c5d 0x58f795 0x510bf2 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x510325 0x5b4ee6 0x6005a3 0x607796 0x60785c 0x60a436 0x64db82 0x64dd2e 0x7f99eb0d5c87 0x5b636a\n",
            "preprocessing3.py:98: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  data=np.array(data)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "HJhmP3VUa8ls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fQO-gMBfpeU",
        "outputId": "7ec40514-71bb-4f27-8b5d-6c5797031dc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.9.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install h5py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpVOv0VJjzS0",
        "outputId": "4163418c-0291-4680-c281-ddd82e0ed2d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.21.6)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "# from tensorflow.keras.models import Sequential\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, MaxPooling1D, Convolution1D, Embedding\n",
        "from keras.layers import Concatenate\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "from keras import regularizers\n",
        "import joblib\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "metadata": {
        "id": "rxdkzqaabV2c"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_to_ix=np.load('label_to_ix.npy', allow_pickle=True).item()\n",
        "ix_to_label=np.load('ix_to_label.npy', allow_pickle=True)\n",
        "training_data=np.load('training_data.npy', allow_pickle=True)\n",
        "test_data=np.load('test_data.npy', allow_pickle=True)\n",
        "val_data=np.load('val_data.npy', allow_pickle=True)\n",
        "word_to_ix=np.load('word_to_ix.npy', allow_pickle=True).item()\n",
        "ix_to_word=np.load('ix_to_word.npy', allow_pickle=True)\n",
        "newwikivec=np.load('newwikivec.npy', allow_pickle=True)"
      ],
      "metadata": {
        "id": "QSOAb8jcgRIr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM Base Model - Without wiki data"
      ],
      "metadata": {
        "id": "U4gJ_4Ssw4Px"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model:\n",
        "\n",
        "EMBEDDING_SIZE = 100\n",
        "hidden_dim=500\n",
        "maxlen = 200\n",
        "MAX_SEQ_LENGTH = 100\n",
        "MAX_VOCAB = len(word_to_ix)\n",
        "num_classes = len(label_to_ix)\n",
        "\n",
        "def build_cnn_model(input_length, embedding_size, max_vocab, num_filters, filter_sizes, training_dropout_keep_prob, num_classes):\n",
        "  model_input = Input(shape=input_length)\n",
        "  z =  Embedding(max_vocab + 1, embedding_size,input_length=input_length, embeddings_regularizer=regularizers.l2(0.0001),name=\"embedding\")(model_input)\n",
        "  # Convolutional block\n",
        "  conv_blocks = []\n",
        "  for sz in filter_sizes:\n",
        "      conv = Convolution1D(filters=num_filters,                         \n",
        "                        kernel_size=sz,\n",
        "                        padding=\"valid\",\n",
        "                        activation=\"relu\",\n",
        "                        strides=1)(z)\n",
        "      window_pool_size =  input_length  - sz + 1 \n",
        "      conv = MaxPooling1D(pool_size=window_pool_size)(conv)  \n",
        "      conv = Flatten()(conv)\n",
        "      conv_blocks.append(conv)\n",
        "  #concatenate\n",
        "  z = Concatenate()(conv_blocks) if len(conv_blocks) > 1 else conv_blocks[0]\n",
        "  z = Dropout(training_dropout_keep_prob)(z)\n",
        "  # z = Dense(hidden_dim, activation=\"relu\")(z)\n",
        "  model_output = Dense(num_classes, activation=\"sigmoid\")(z)\n",
        "\n",
        "  model = Model(model_input, model_output)\n",
        "  model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "  # print(model.summary())\n",
        "  return model\n",
        "def build_lstm_model(input_length, embedding_size, max_vocab, num_filters, filter_sizes, training_dropout_keep_prob, num_classes):\n",
        "  model_input = Input(shape=input_length)\n",
        "  model = keras.models.Sequential()\n",
        "  model.add(Embedding(max_vocab + 1, embedding_size, input_length=input_length, embeddings_regularizer=regularizers.l2(0.0001),name=\"embedding\"))\n",
        "  model.add(layers.LSTM(64, dropout=0.1))\n",
        "  model.add(layers.Dense(num_classes, activation=\"sigmoid\"))\n",
        "  model.summary()\n",
        "  loss = keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "  optim = keras.optimizers.Adam(learning_rate=0.001)\n",
        "  metrics = [\"accuracy\"]\n",
        "  model.compile(loss=loss, optimizer=optim, metrics=metrics)  \n",
        "  return model"
      ],
      "metadata": {
        "id": "oisFNm6mf-_k"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cnn_model = build_cnn_model(input_length=MAX_SEQ_LENGTH, embedding_size=EMBEDDING_SIZE, max_vocab = MAX_VOCAB, num_filters = 100, filter_sizes=[2,3,4,5],\n",
        "#                              training_dropout_keep_prob=0.5, num_classes = num_classes)\n",
        "# print(cnn_model.summary())\n",
        "lstm_model = build_lstm_model(input_length=MAX_SEQ_LENGTH, embedding_size=EMBEDDING_SIZE, max_vocab = MAX_VOCAB, num_filters = 100, filter_sizes=[2,3,4,5],\n",
        "                             training_dropout_keep_prob=0.5, num_classes = num_classes)\n",
        "print(lstm_model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zl27LYIHk7a8",
        "outputId": "aec0bc03-a31a-401d-f2c3-f29a0298b45e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 100)          4796100   \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 64)                42240     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 344)               22360     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,860,700\n",
            "Trainable params: 4,860,700\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 100)          4796100   \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 64)                42240     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 344)               22360     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,860,700\n",
            "Trainable params: 4,860,700\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import plot_model\n",
        "from IPython.display import Image\n",
        "plot_model(lstm_model,'lstm_base.png')\n",
        "Image('lstm_base.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "gClQuAmYeRj6",
        "outputId": "aaf314e3-b045-46e6-f9d2-c141bbd9c158"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = [len(x[0]) for x in training_data]"
      ],
      "metadata": {
        "id": "Uc5SoFJbpkWz"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min(count), max(count), np.mean(count), np.median(count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okqjQs7Up0Li",
        "outputId": "b69d31a6-a85a-4901-a3a0-f67efe2ecb1d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36, 5285, 1023.7772870149578, 937.0)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(input_data):\n",
        "  # training_data is of the form (list of list of words, notes, y )\n",
        "  #training_data[0]\n",
        "  #array([list(['admission', 'date', 'discharge', 'date', 'date', \n",
        "  #array([1., 1., 1., ..., 0., 0., 0.]),\n",
        "       #list(['d_427', 'd_423', 'd_458', 'd_401', 'd_272', 'd_250', 'd_424'])],\n",
        "  x_data =  [[word_to_ix[x] for x in record[0] if x in word_to_ix] for record in input_data]\n",
        "  x_data = tf.keras.utils.pad_sequences(x_data, maxlen=MAX_SEQ_LENGTH, padding=\"post\")\n",
        "  y_data = [[label_to_ix[x] for x in record[2] if x in label_to_ix] for record in input_data]\n",
        "  ylabel_count = np.array([len(item) for item in y_data])\n",
        "  arg_zero = np.argwhere(ylabel_count == 0)\n",
        "  y_data = [y_data[i] for i in range(len(y_data)) if i not in arg_zero]\n",
        "  x_data = [x_data[i] for i in range(len(x_data)) if i not in arg_zero]\n",
        "  x_data = np.array(x_data)\n",
        "  for idx, item in enumerate(y_data):\n",
        "    y = np.zeros(len(label_to_ix),)\n",
        "    y[item] = 1\n",
        "    y_data[idx] = y\n",
        "  y_data = np.array(y_data)\n",
        "  return x_data, y_data"
      ],
      "metadata": {
        "id": "QKFRCopwC9Cn"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x, train_y = get_data(training_data)"
      ],
      "metadata": {
        "id": "TDeELfOuHUxU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y.shape, train_x.shape\n",
        "# ((34898, 344), (34898, 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnK99Or-zr_0",
        "outputId": "d64cb525-39f8-42b9-c1a8-4706ce98c922"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((34898, 344), (34898, 100))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_x, val_y = get_data(val_data)\n",
        "test_x, test_y = get_data(test_data)"
      ],
      "metadata": {
        "id": "JwF7Suu7OEXL"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_y.shape, val_x.shape, test_y.shape, test_x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aeb2C0jOmDv",
        "outputId": "f091345e-cbdd-4209-9def-fdeca42a9099"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5022, 344), (5022, 100), (9985, 344), (9985, 100))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_lstm_model(train_x, train_y, val_x, val_y, batch_size=50, epochs=20):\n",
        "  tf.config.run_functions_eagerly(True) # https://stackoverflow.com/questions/58352326/running-the-tensorflow-2-0-code-gives-valueerror-tf-function-decorated-functio\n",
        "  lstm_model.fit(train_x, train_y, validation_data=(val_x, val_y), batch_size=batch_size, epochs=epochs, verbose=2)\n",
        "  # save model\n",
        "  lstm_model.save('lstm_20_epochs.h5')"
      ],
      "metadata": {
        "id": "YdDqW_b607yH"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "path='lstm_20_epochs.h5'\n",
        "isExist = os.path.exists(path)\n",
        "isExist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-t_Fuk6SJLtw",
        "outputId": "0425e3fd-6566-410e-97a6-df77b15a4c57"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "if not isExist:\n",
        "  train_lstm_model(train_x, train_y, val_x, val_y, batch_size=50, epochs=20)\n",
        "\n",
        "model = load_model('lstm_20_epochs.h5')\n"
      ],
      "metadata": {
        "id": "rpPkfh8yJYxy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05abc540-ba6b-4fb3-d280-cbe4e8809f9d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/structured_function.py:265: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "698/698 - 254s - loss: 0.0933 - accuracy: 0.0343 - val_loss: 0.0560 - val_accuracy: 0.0337 - 254s/epoch - 363ms/step\n",
            "Epoch 2/20\n",
            "698/698 - 251s - loss: 0.0566 - accuracy: 0.0359 - val_loss: 0.0557 - val_accuracy: 0.0337 - 251s/epoch - 360ms/step\n",
            "Epoch 3/20\n",
            "698/698 - 243s - loss: 0.0566 - accuracy: 0.0359 - val_loss: 0.0558 - val_accuracy: 0.0337 - 243s/epoch - 347ms/step\n",
            "Epoch 4/20\n",
            "698/698 - 249s - loss: 0.0566 - accuracy: 0.0359 - val_loss: 0.0557 - val_accuracy: 0.0337 - 249s/epoch - 357ms/step\n",
            "Epoch 5/20\n",
            "698/698 - 251s - loss: 0.0564 - accuracy: 0.0358 - val_loss: 0.0554 - val_accuracy: 0.0337 - 251s/epoch - 360ms/step\n",
            "Epoch 6/20\n",
            "698/698 - 242s - loss: 0.0560 - accuracy: 0.0363 - val_loss: 0.0551 - val_accuracy: 0.0337 - 242s/epoch - 346ms/step\n",
            "Epoch 7/20\n",
            "698/698 - 241s - loss: 0.0559 - accuracy: 0.0361 - val_loss: 0.0551 - val_accuracy: 0.0337 - 241s/epoch - 345ms/step\n",
            "Epoch 8/20\n",
            "698/698 - 241s - loss: 0.0558 - accuracy: 0.0363 - val_loss: 0.0551 - val_accuracy: 0.0337 - 241s/epoch - 346ms/step\n",
            "Epoch 9/20\n",
            "698/698 - 250s - loss: 0.0558 - accuracy: 0.0358 - val_loss: 0.0550 - val_accuracy: 0.0337 - 250s/epoch - 358ms/step\n",
            "Epoch 10/20\n",
            "698/698 - 241s - loss: 0.0557 - accuracy: 0.0366 - val_loss: 0.0550 - val_accuracy: 0.0337 - 241s/epoch - 345ms/step\n",
            "Epoch 11/20\n",
            "698/698 - 241s - loss: 0.0557 - accuracy: 0.0369 - val_loss: 0.0549 - val_accuracy: 0.0346 - 241s/epoch - 345ms/step\n",
            "Epoch 12/20\n",
            "698/698 - 239s - loss: 0.0556 - accuracy: 0.0369 - val_loss: 0.0548 - val_accuracy: 0.0544 - 239s/epoch - 343ms/step\n",
            "Epoch 13/20\n",
            "698/698 - 241s - loss: 0.0555 - accuracy: 0.0375 - val_loss: 0.0547 - val_accuracy: 0.0339 - 241s/epoch - 345ms/step\n",
            "Epoch 14/20\n",
            "698/698 - 249s - loss: 0.0556 - accuracy: 0.0406 - val_loss: 0.0544 - val_accuracy: 0.0346 - 249s/epoch - 357ms/step\n",
            "Epoch 15/20\n",
            "698/698 - 239s - loss: 0.0552 - accuracy: 0.0488 - val_loss: 0.0545 - val_accuracy: 0.0404 - 239s/epoch - 343ms/step\n",
            "Epoch 16/20\n",
            "698/698 - 241s - loss: 0.0550 - accuracy: 0.0572 - val_loss: 0.0541 - val_accuracy: 0.0564 - 241s/epoch - 345ms/step\n",
            "Epoch 17/20\n",
            "698/698 - 239s - loss: 0.0548 - accuracy: 0.0686 - val_loss: 0.0541 - val_accuracy: 0.0798 - 239s/epoch - 343ms/step\n",
            "Epoch 18/20\n",
            "698/698 - 240s - loss: 0.0547 - accuracy: 0.0875 - val_loss: 0.0537 - val_accuracy: 0.0972 - 240s/epoch - 344ms/step\n",
            "Epoch 19/20\n",
            "698/698 - 249s - loss: 0.0542 - accuracy: 0.1032 - val_loss: 0.0532 - val_accuracy: 0.1000 - 249s/epoch - 357ms/step\n",
            "Epoch 20/20\n",
            "698/698 - 239s - loss: 0.0538 - accuracy: 0.1095 - val_loss: 0.0530 - val_accuracy: 0.0974 - 239s/epoch - 342ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction for training data\n",
        "pred_train = model.predict(train_x, batch_size=50)\n",
        "pred_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LV7qwd6fWsSB",
        "outputId": "15f73ce7-2955-49d0-9616-893c8d98e091"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "698/698 [==============================] - 74s 105ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.3325383e-02, 5.1359430e-02, 1.4788611e-02, ..., 1.7221306e-05,\n",
              "        1.7390237e-05, 1.2239392e-05],\n",
              "       [1.5321411e-01, 7.2472662e-02, 6.6479690e-02, ..., 3.5813078e-05,\n",
              "        7.4460382e-05, 1.1525714e-04],\n",
              "       [1.1186317e-01, 6.2642165e-02, 4.1533012e-02, ..., 3.6837137e-05,\n",
              "        5.7538124e-05, 5.8692094e-05],\n",
              "       ...,\n",
              "       [1.5129659e-01, 7.9013862e-02, 3.7823983e-02, ..., 2.2268108e-05,\n",
              "        3.3267104e-05, 5.2585790e-05],\n",
              "       [1.5063724e-01, 5.6401730e-02, 3.7409935e-02, ..., 4.4204327e-05,\n",
              "        6.1802530e-05, 3.6403475e-05],\n",
              "       [1.2294548e-01, 7.3935173e-02, 3.4054458e-02, ..., 2.4212017e-05,\n",
              "        3.4356908e-05, 4.1486492e-05]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction for validation data\n",
        "pred_val = model.predict(val_x, batch_size=100)\n",
        "pred_val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LejUsHpeeHnc",
        "outputId": "d558099e-59dc-46c9-b651-8b4cfa312fdf"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51/51 [==============================] - 8s 152ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.58067788e-02, 3.93832810e-02, 6.76699169e-03, ...,\n",
              "        1.15273651e-05, 9.12230189e-06, 4.27317309e-06],\n",
              "       [1.30691439e-01, 7.22649843e-02, 4.74191308e-02, ...,\n",
              "        3.20769250e-05, 5.45916228e-05, 6.82814280e-05],\n",
              "       [9.92466211e-02, 5.40403463e-02, 2.96169817e-02, ...,\n",
              "        2.62037574e-05, 3.53248761e-05, 3.44598739e-05],\n",
              "       ...,\n",
              "       [4.26556282e-02, 2.31563505e-02, 1.19532002e-02, ...,\n",
              "        4.54292713e-05, 4.63442811e-05, 6.27524742e-06],\n",
              "       [1.77508906e-01, 8.24438557e-02, 6.36606067e-02, ...,\n",
              "        2.95609843e-05, 5.61714696e-05, 1.01425467e-04],\n",
              "       [1.18130155e-01, 7.00769946e-02, 3.84424143e-02, ...,\n",
              "        2.97258794e-05, 4.46135491e-05, 4.86438403e-05]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_y.shape, pred_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9M3xH8VeOf7",
        "outputId": "83ad3b62-5f5a-4f05-d115-91eaad61d945"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5022, 344), (5022, 344))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "def get_f1_score(y_actual, pred_val):\n",
        "  y_final = np.where(np.array(pred_val) > 0.005, 1, 0)\n",
        "  f1score_macro = f1_score(np.array(y_actual), y_final, average=\"macro\")\n",
        "  print(f\"f1score_macro = {f1score_macro}\")\n",
        "  f1score_micro = f1_score(np.array(y_actual), y_final, average=\"micro\")\n",
        "  print(f\"f1score_micro = {f1score_micro}\")\n",
        "  return f1score_macro, f1score_micro\n"
      ],
      "metadata": {
        "id": "PLktIN4KXTqn"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# f1score_micro = f1_score(np.array(train_y), y_final, average=\"micro\")\n",
        "# f1score_micro"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XjRr3HTYM6q",
        "outputId": "b7460cc0-6fa2-4aa0-afba-7eb304a19ab1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.12242476441350231"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction for test data\n",
        "pred_test = model.predict(test_x, batch_size=100)\n",
        "pred_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1w2itf_7WBiT",
        "outputId": "5427d7da-f675-4177-c07c-124b303d91cf"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100/100 [==============================] - 16s 161ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.65461928e-01, 7.60063604e-02, 4.62627709e-02, ...,\n",
              "        2.60505476e-05, 4.18949603e-05, 6.67340209e-05],\n",
              "       [1.26163423e-01, 6.21519946e-02, 3.95148844e-02, ...,\n",
              "        3.05543435e-05, 4.60312513e-05, 5.44732065e-05],\n",
              "       [3.37379277e-02, 3.63198780e-02, 6.03366829e-03, ...,\n",
              "        1.43468333e-05, 1.08800405e-05, 3.38366385e-06],\n",
              "       ...,\n",
              "       [3.61754633e-02, 3.83890308e-02, 6.60831761e-03, ...,\n",
              "        1.04840719e-05, 8.21175945e-06, 4.21703044e-06],\n",
              "       [8.82292166e-02, 5.82469851e-02, 2.23451518e-02, ...,\n",
              "        1.90827122e-05, 2.31694630e-05, 2.33415376e-05],\n",
              "       [1.19323097e-01, 6.37281835e-02, 2.92641167e-02, ...,\n",
              "        2.29354901e-05, 2.93504199e-05, 3.29376962e-05]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1score_macro, f1score_micro = get_f1_score(val_y, pred_val)\n",
        "f1score_macro, f1score_micro"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFNDZFIhdkFL",
        "outputId": "34aaa9d4-d75d-478d-8fc8-a6753ed3c347"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1score_macro = 0.031046365427069483\n",
            "f1score_micro = 0.09808448578341868\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.031046365427069483, 0.09808448578341868)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1score_test_macro, f1score_test_micro = get_f1_score(test_y, pred_test)\n",
        "f1score_test_macro, f1score_test_micro"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jg74W7Ploj6p",
        "outputId": "9eceb194-f411-4d6d-c1f8-64113dbc5909"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1score_macro = 0.03189100053739335\n",
            "f1score_micro = 0.09892578098710417\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.03189100053739335, 0.09892578098710417)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_final = np.where(np.array(pred_val) > 0.005, 1, 0)\n",
        "print(len(np.unique(y_final)))\n",
        "print(len(np.unique(val_y)))\n",
        "# auc_macro = roc_auc_score(val_y, y_final, average=\"macro\", multi_class=\"ovo\")\n",
        "# print(f\"auc_macro = {auc_macro}\")\n",
        "auc_micro = roc_auc_score(val_y, y_final, average=\"micro\")\n",
        "print(f\"auc_micro = {auc_micro}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3Hk4FMvf7WF",
        "outputId": "8ec7f9f0-5756-4287-c864-9127247e12ae"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "2\n",
            "auc_micro = 0.833928807368601\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_final_test = np.where(np.array(pred_test) > 0.005, 1, 0)\n",
        "print(len(np.unique(y_final_test)))\n",
        "print(len(np.unique(test_y)))\n",
        "# auc_macro = roc_auc_score(test_y, y_final_test, average=\"macro\", multi_class=\"ovo\")\n",
        "# print(f\"auc_macro = {auc_macro}\")\n",
        "auc_micro = roc_auc_score(test_y, y_final_test, average=\"micro\")\n",
        "print(f\"auc_micro = {auc_micro}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKqqCBTcYhNq",
        "outputId": "20c0a6af-5465-48e6-bede-4e5440756fcf"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "2\n",
            "auc_micro = 0.8327903475643806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models from Original Paper"
      ],
      "metadata": {
        "id": "9I5d6ogBxH0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python KSI_CNN.py"
      ],
      "metadata": {
        "id": "Yz_saJK6oX3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd8240e6-82e2-4382-e3d8-612c57161043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KSI_CNN.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  new_data=np.array(new_data)\n",
            "KSI_CNN.py:57: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  main_matrix = np.zeros((mybsize, numword), dtype= np.int)\n",
            "start_training\n",
            "0\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.447759546015512\n",
            "1\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.5463922233608504\n",
            "2\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.5869477961874576\n",
            "3\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.6122995587404496\n",
            "4\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.6422864593906304\n",
            "5\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.6617816478566985\n",
            "6\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.6757633827794965\n",
            "7\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.6923966392728145\n",
            "8\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7061567372641866\n",
            "9\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7151707140469439\n",
            "10\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7210076915653125\n",
            "11\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7297049877302053\n",
            "12\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7331820806872247\n",
            "13\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7365242396154984\n",
            "14\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7438993480615125\n",
            "15\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7454819630849553\n",
            "16\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7461523181315273\n",
            "17\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7476686868566037\n",
            "18\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7499788258537549\n",
            "19\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7536500680597897\n",
            "20\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7548689356360647\n",
            "21\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7559340685346785\n",
            "22\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7571428727644128\n",
            "23\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7577222458278956\n",
            "24\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.755937462559222\n",
            "25\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7575183804216735\n",
            "26\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7567200712804484\n",
            "27\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7556417372362435\n",
            "28\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7561210822650272\n",
            "[0.447759546015512, 0.5463922233608504, 0.5869477961874576, 0.6122995587404496, 0.6422864593906304, 0.6617816478566985, 0.6757633827794965, 0.6923966392728145, 0.7061567372641866, 0.7151707140469439, 0.7210076915653125, 0.7297049877302053, 0.7331820806872247, 0.7365242396154984, 0.7438993480615125, 0.7454819630849553, 0.7461523181315273, 0.7476686868566037, 0.7499788258537549, 0.7536500680597897, 0.7548689356360647, 0.7559340685346785, 0.7571428727644128, 0.7577222458278956, 0.755937462559222, 0.7575183804216735, 0.7567200712804484, 0.7556417372362435, 0.7561210822650272] 23\n",
            "start_training\n",
            "0\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7697776387548377\n",
            "1\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7745830347368206\n",
            "2\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7790220714260897\n",
            "3\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7809155243476594\n",
            "4\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.783218725025504\n",
            "5\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7835059702997416\n",
            "6\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7829316702307447\n",
            "7\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7813091366856753\n",
            "8\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.781788900439549\n",
            "9\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7809344594810457\n",
            "10\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.777941154173852\n",
            "[0.7697776387548377, 0.7745830347368206, 0.7790220714260897, 0.7809155243476594, 0.783218725025504, 0.7835059702997416, 0.7829316702307447, 0.7813091366856753, 0.781788900439549, 0.7809344594810457, 0.777941154173852] 5\n",
            "CNN alone:           \n",
            "KSI_CNN.py:296: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y_pred=(y_scores>0.5).astype(np.int)\n",
            "test loss 0.03901169\n",
            "top- 10 0.7500204603362106\n",
            "macro AUC 0.8312319298310952\n",
            "micro AUC 0.9656105557742741\n",
            "macro F1 0.21103060111847347\n",
            "micro F1 0.6225067502830763\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "KSI+CNN:           \n",
            "KSI_CNN.py:296: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y_pred=(y_scores>0.5).astype(np.int)\n",
            "test loss 0.034980208\n",
            "top- 10 0.7812795295965008\n",
            "macro AUC 0.87048521579638\n",
            "micro AUC 0.9736050470496298\n",
            "macro F1 0.2498243106070881\n",
            "micro F1 0.6434982863981722\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python KSI_LSTM.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQVabYxpN-Sl",
        "outputId": "3c61dfe4-a8c7-4641-e6a6-61f1ffe393f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KSI_LSTM.py:42: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  new_data=np.array(new_data)\n",
            "KSI_LSTM.py:56: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  main_matrix = np.zeros((mybsize, numword), dtype= np.int)\n",
            "start_training\n",
            "0\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.4288319600440542\n",
            "1\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.49612631506771865\n",
            "2\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.5371347397996127\n",
            "3\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.57960611939744\n",
            "4\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.6060135762942431\n",
            "5\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.6306258634506745\n",
            "6\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.6529176350147726\n",
            "7\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.6650854147296982\n",
            "8\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.6776047413733818\n",
            "9\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.6885564256977353\n",
            "10\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.6986521278980811\n",
            "11\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7030694364234735\n",
            "12\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7123422624852275\n",
            "13\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7180066227334836\n",
            "14\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7228353739341756\n",
            "15\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7253831336542651\n",
            "16\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.732078014625066\n",
            "17\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7380664659954834\n",
            "18\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7391607743819303\n",
            "19\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7433243865083464\n",
            "20\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7440340243947641\n",
            "21\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7454775971945329\n",
            "22\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.748999388471214\n",
            "23\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7498219216181418\n",
            "24\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7525390306737908\n",
            "25\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7543717731209019\n",
            "26\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7569278331575957\n",
            "27\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.757324332479805\n",
            "28\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7601317011960999\n",
            "29\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7565299421569608\n",
            "30\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7595054744603529\n",
            "Traceback (most recent call last):\n",
            "  File \"KSI_LSTM.py\", line 225, in <module>\n",
            "    basemodel= trainmodel(model, 0)\n",
            "  File \"KSI_LSTM.py\", line 170, in trainmodel\n",
            "    tag_scores = model(mysentence[0].cuda(),mysentence[1].cuda(),wikivec.cuda(),sim)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python KSI_LSTMatt.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "en55s1nPOBQ-",
        "outputId": "acb344bf-c354-425d-9b1f-3c522dfb6bef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KSI_LSTMatt.py:42: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  new_data=np.array(new_data)\n",
            "KSI_LSTMatt.py:56: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  main_matrix = np.zeros((mybsize, numword), dtype= np.int)\n",
            "start_training\n",
            "0\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.3796880833045024\n",
            "1\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.5110696636997789\n",
            "2\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.6093055428192424\n",
            "3\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.6572779123564315\n",
            "4\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.6913102760352287\n",
            "5\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.712381054140963\n",
            "6\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7319656780423488\n",
            "7\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7490557300327217\n",
            "8\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7648167395299731\n",
            "9\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7701526572533232\n",
            "10\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7730448759900487\n",
            "11\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7802758508102225\n",
            "12\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7834162074668065\n",
            "13\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7871388343424428\n",
            "14\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7905063480623135\n",
            "15\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7922422765221323\n",
            "16\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7941588853586284\n",
            "17\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7925567496754249\n",
            "18\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7952998549125266\n",
            "19\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7950354012869386\n",
            "20\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7939392185467694\n",
            "21\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7964898564680106\n",
            "22\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7928819255311822\n",
            "23\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7934365995499347\n",
            "24\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7917423948264123\n",
            "25\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7901647969657816\n",
            "26\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7915144060081255\n",
            "[0.3796880833045024, 0.5110696636997789, 0.6093055428192424, 0.6572779123564315, 0.6913102760352287, 0.712381054140963, 0.7319656780423488, 0.7490557300327217, 0.7648167395299731, 0.7701526572533232, 0.7730448759900487, 0.7802758508102225, 0.7834162074668065, 0.7871388343424428, 0.7905063480623135, 0.7922422765221323, 0.7941588853586284, 0.7925567496754249, 0.7952998549125266, 0.7950354012869386, 0.7939392185467694, 0.7964898564680106, 0.7928819255311822, 0.7934365995499347, 0.7917423948264123, 0.7901647969657816, 0.7915144060081255] 21\n",
            "start_training\n",
            "0\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.8050618299416882\n",
            "1\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.8087069770231602\n",
            "2\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.8121895666324257\n",
            "3\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.8125589393620954\n",
            "4\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.8122919644275569\n",
            "5\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.8111489062427737\n",
            "6\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.809490758053944\n",
            "7\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.8094009200463553\n",
            "8\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.807479054481567\n",
            "[0.8050618299416882, 0.8087069770231602, 0.8121895666324257, 0.8125589393620954, 0.8122919644275569, 0.8111489062427737, 0.809490758053944, 0.8094009200463553, 0.807479054481567] 3\n",
            "LSTMattn alone:           \n",
            "KSI_LSTMatt.py:299: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y_pred=(y_scores>0.5).astype(np.int)\n",
            "test loss 0.035679273\n",
            "top- 10 0.7890955665519177\n",
            "macro AUC 0.8471586694123668\n",
            "micro AUC 0.9739016293528034\n",
            "macro F1 0.2479528389006514\n",
            "micro F1 0.6435407087266642\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "KSI+LSTMattn:           \n",
            "KSI_LSTMatt.py:299: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y_pred=(y_scores>0.5).astype(np.int)\n",
            "test loss 0.0327006\n",
            "top- 10 0.8033933083742822\n",
            "macro AUC 0.8869315218841526\n",
            "micro AUC 0.977975293333773\n",
            "macro F1 0.2948724435620207\n",
            "micro F1 0.6617492987258777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python KSI_CAML.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDROr_Gw3Xqj",
        "outputId": "42d5e641-ff23-4929-fd13-bf8621c6cd25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KSI_CAML.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  new_data=np.array(new_data)\n",
            "KSI_CAML.py:57: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  main_matrix = np.zeros((mybsize, numword), dtype= np.int)\n",
            "start_training\n",
            "0\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.6044048484082241\n",
            "1\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7351386587887544\n",
            "2\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7708715147202543\n",
            "3\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7896376400647074\n",
            "4\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.7972106688739532\n",
            "5\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.8031287366802995\n",
            "6\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.8069326762550824\n",
            "7\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.8055677895487277\n",
            "8\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.8053297325208615\n",
            "9\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.8063642871379448\n",
            "10\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.8090197694390706\n",
            "11\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.8092199470698243\n",
            "12\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.8101487634371684\n",
            "13\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.8113517289815019\n",
            "14\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.8116583075427964\n",
            "15\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.8104984101565177\n",
            "16\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.8100182952683771\n",
            "17\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.808002453091821\n",
            "18\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.805693506951576\n",
            "19\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.8057614128038348\n",
            "[0.6044048484082241, 0.7351386587887544, 0.7708715147202543, 0.7896376400647074, 0.7972106688739532, 0.8031287366802995, 0.8069326762550824, 0.8055677895487277, 0.8053297325208615, 0.8063642871379448, 0.8090197694390706, 0.8092199470698243, 0.8101487634371684, 0.8113517289815019, 0.8116583075427964, 0.8104984101565177, 0.8100182952683771, 0.808002453091821, 0.805693506951576, 0.8057614128038348] 14\n",
            "start_training\n",
            "0\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.8140266255254831\n",
            "1\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.8147091382076955\n",
            "2\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.8170125045297363\n",
            "3\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.8182234205097768\n",
            "4\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.8171049411193342\n",
            "5\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.8175013924988754\n",
            "6\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.8159682510283893\n",
            "7\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.8140574932786019\n",
            "8\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "validation top- 10 0.8104559403705842\n",
            "[0.8140266255254831, 0.8147091382076955, 0.8170125045297363, 0.8182234205097768, 0.8171049411193342, 0.8175013924988754, 0.8159682510283893, 0.8140574932786019, 0.8104559403705842] 3\n",
            "CAML alone:           \n",
            "KSI_CAML.py:290: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y_pred=(y_scores>0.5).astype(np.int)\n",
            "test loss 0.0331816\n",
            "top- 10 0.8082227943470723\n",
            "macro AUC 0.8531734147062066\n",
            "micro AUC 0.9782101645827287\n",
            "macro F1 0.281852134831064\n",
            "micro F1 0.6581356098693552\n",
            "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
            "KSI+CAML:           \n",
            "KSI_CAML.py:290: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y_pred=(y_scores>0.5).astype(np.int)\n",
            "test loss 0.03233041\n",
            "top- 10 0.81482262907353\n",
            "macro AUC 0.8824331455916562\n",
            "micro AUC 0.9801271600924634\n",
            "macro F1 0.2968179130496338\n",
            "micro F1 0.6652959265571878\n"
          ]
        }
      ]
    }
  ]
}